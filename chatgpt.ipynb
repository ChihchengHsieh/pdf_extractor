{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04d696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  33%|███▎      | 1/3 [00:28<00:57, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q1': 'Ahn 2020', 'Q2': 'Causal Inference between Rheumatoid Arthritis and Breast Cancer in East Asian and European Population: A Two-Sample Mendelian Randomization', 'Q3': 'Cancers', 'Q4': '2020', 'Q5': 'Two-sample MR', 'Q6': 'SNPs from six genome-wide association studies (GWAS) targeting RA in an East Asian population, and GWAS-summary results from the BBJ, BCAC, and CIMBA for breast cancer', 'Q7': '25', 'Q8': 'Rheumatoid Arthritis', 'Q9': 'Breast Cancer', 'Q10': '1', 'Q11': '1', 'Q12': 'Six different GWAS targeting RA in an East Asian population', 'Q13': 'BBJ (BioBank Japan), BCAC (Breast Cancer Association Consortium), and CIMBA (Consortium of Investigators of Modifiers of BRCA1/2)', 'Q14': 'The East Asian RA GWAS included six different studies with sample sizes ranging from 100 to 7907 RA cases and controls varying proportionally .', 'Q15': 'BCAC: 122,977 cases and 105,974 controls; CIMBA: 15,252 BRCA1 and 8211 BRCA2 carriers', 'Q16': 'East Asian (Korean and Japanese)【4:6†source】', 'Q17': 'European【4:6†source】', 'Q18': 'Yes', 'Q19': 'East Asia, Europe', 'Q20': 'R, Mendelian randomization package'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  67%|██████▋   | 2/3 [01:03<00:32, 32.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q1': 'Aoki 2022', 'Q2': 'Shared genetic components between metabolic syndrome and schizophrenia: Genetic correlation using multipopulation data sets', 'Q3': 'Psychiatry and Clinical Neurosciences', 'Q4': '2022', 'Q5': 'Two-sample MR', 'Q6': 'SNPs involved in the 1000 Genomes Project and HapMap Projects, with a minor allele frequency ≥ 1%, and INFO ≥0.9', 'Q7': 'NA', 'Q8': 'Metabolic syndrome traits (BMI, HDL-C, blood sugar, triglycerides, systolic blood pressure, CRP)', 'Q9': 'Schizophrenia (SCZ)', 'Q10': '1', 'Q11': '1', 'Q12': 'JENGER database provided by Biobank Japan', 'Q13': 'PGC for EUR samples, PGC Asia for EAS samples', 'Q14': 'EAS: 24,504 (SCZ patients) and 42,770 (controls), EUR: Varies with trait, up to 361,194 samples', 'Q15': 'EAS: 24,504 (SCZ patients) and 42,770 (controls), EUR: Varies with trait, up to 361,194 samples', 'Q16': 'East Asian', 'Q17': 'European', 'Q18': 'Yes', 'Q19': 'East Asia, Europe', 'Q20': 'TwoSample MR, LDSC software'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 3/3 [01:45<00:00, 35.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q1': 'AuYeung 2023', 'Q2': 'Evaluating the role of non-alcoholic fatty liver disease in cardiovascular diseases and type 2 diabetes: a Mendelian randomization study in Europeans and East Asians', 'Q3': 'International Journal of Epidemiology', 'Q4': '2023', 'Q5': 'Two-sample MR', 'Q6': 'Genetic predictors of ALT, liability to NAFLD, AST, liver MRI cT1, proton density fat fraction, 195 ALT instruments, 228 AST instruments【4:9†source】', 'Q7': 'ALT: 195, AST: 228, cT1: 5, PDFF: 4【4:9†source】', 'Q8': 'ALT (alanine aminotransferase), liability to NAFLD (non-alcoholic fatty liver disease), AST (aspartate transaminase), liver MRI cT1, proton density fat fraction【4:0†source】', 'Q9': 'Cardiovascular diseases (CVD), type 2 diabetes (T2D), coronary artery disease (CAD) stroke, atrial fibrillation, heart failure【4:6†source】', 'Q10': '5', 'Q11': '6', 'Q12': 'Neale Lab in the UK Biobank, Million Veteran Program, UK Biobank for cT1 and PDFF【4:4†source】', 'Q13': 'DIAMANTE consortium, MAGIC, CARDIoGRAM, MEGASTROKE, HERMES consortium【4:6†source】', 'Q14': 'GWAS for ALT: 344,292 participants; liability to NAFLD: 164,197; cT1 and PDFF: 14,440【4:4†source】', 'Q15': 'DIAMANTE consortium for T2D: existing samples of 977,320; GWAS for CVD: existing samples of 520K-1M; heart failure: existing samples from HERMES consortium【4:6†source】', 'Q16': 'European【4:4†source】', 'Q17': 'European, East Asian【4:19†source】', 'Q18': 'Yes', 'Q19': 'UK, Japan【4:19†source】', 'Q20': 'TwoSampleMR, R【4:19†source】'}\n",
      "\n",
      "✅ Saved extracted data to: extracted_mr_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from secret import OPENAI_API_KEY\n",
    "\n",
    "import re\n",
    "def extract_json_objects(text):\n",
    "    # Try to load full string as a list of dicts\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        if isinstance(data, list):\n",
    "            return data[0]\n",
    "        else:\n",
    "            return data\n",
    "    except json.JSONDecodeError:\n",
    "        pass  # Try regex fallback below\n",
    "\n",
    "    # Fallback regex in case it's not clean JSON\n",
    "    pattern = r'\\{(?:[^{}]|(?R))*\\}'  # recursively match nested {}\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    objects = []\n",
    "    for m in matches:\n",
    "        try:\n",
    "            obj = json.loads(m)\n",
    "            objects.append(obj)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "    return objects[0]\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = OPENAI_API_KEY  # Ensure this environment variable is set\n",
    "\n",
    "# Paths\n",
    "pdf_dir = \"./documents\"\n",
    "prompt_path = \"./templates/example.txt\"\n",
    "output_csv = \"chatgpt_extracted_mr_data.csv\"\n",
    "\n",
    "# Load base prompt\n",
    "with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    base_prompt = f.read()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(\n",
    "    api_key=openai.api_key,\n",
    ")\n",
    "\n",
    "# Create an assistant with file search capability\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"MR Study Extractor\",\n",
    "    instructions=base_prompt,\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "\n",
    "# Function to process a single PDF file\n",
    "def process_pdf(file_path):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Upload the PDF file\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        uploaded_file = client.files.create(file=f, purpose=\"assistants\")\n",
    "\n",
    "    # Create a new thread\n",
    "    thread = client.beta.threads.create()\n",
    "\n",
    "    # Add a message to the thread with the uploaded file\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Please extract the answers to Q1–Q20 from the attached MR study.\",\n",
    "        attachments=[\n",
    "            {\n",
    "                \"file_id\": uploaded_file.id,\n",
    "                \"tools\": [{\"type\": \"file_search\"}]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Run the assistant\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "    )\n",
    "\n",
    "    # Wait for the run to complete\n",
    "    while True:\n",
    "        run_status = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id, run_id=run.id\n",
    "        )\n",
    "        if run_status.status == \"completed\":\n",
    "            break\n",
    "        elif run_status.status == \"failed\":\n",
    "            print(f\"[ERROR] Run failed for {file_name}\")\n",
    "            return None\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Retrieve the messages\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    response = messages.data[0].content[0].text.value\n",
    "\n",
    "    # Parse the JSON response\n",
    "\n",
    "    data = extract_json_objects(response)\n",
    "    data[\"source_file\"] = file_name\n",
    "    return data\n",
    "\n",
    "\n",
    "# Process all PDFs in the directory\n",
    "results = []\n",
    "pdf_files = sorted([f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")])\n",
    "\n",
    "for pdf_file in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    result = process_pdf(pdf_path)\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "# Save results to CSV\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n✅ Saved extracted data to: {output_csv}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No data extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c67730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ababe66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7575acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a46620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
